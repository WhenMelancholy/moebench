{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2579344/2603555335.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  logits = torch.load(\"output/logits/baseline.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new logits shape torch.Size([16, 2693448, 64])\n",
      "selected_experts shape torch.Size([16, 2693448, 8])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.chdir(\"/n/home08/zkong/mufan/tmp/moebench/open-instruct\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "logits = torch.load(\"output/logits/baseline.pt\")\n",
    "print(\"new logits shape\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_experts shape torch.Size([16, 2693448, 8])\n",
      "expert_frequency shape torch.Size([16, 64])\n",
      "expert_frequency tensor([[837906, 154755, 173987,  ..., 348036, 173925, 492011],\n",
      "        [274722, 665449, 211892,  ..., 220395, 358158, 429618],\n",
      "        [246277, 669706,  89201,  ..., 220317, 326267, 408857],\n",
      "        ...,\n",
      "        [279226, 417342, 299125,  ..., 459584,  65043, 370525],\n",
      "        [268925, 416823, 506604,  ..., 156116, 415473, 488598],\n",
      "        [135508, 189362, 441918,  ..., 424252, 297283, 569011]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "selected_experts = torch.topk(logits, k=8, dim=-1).indices\n",
    "print(\"selected_experts shape\", selected_experts.shape)\n",
    "expert_frequency = torch.zeros((selected_experts.shape[0], 64), dtype=torch.int32)\n",
    "for i in range(selected_experts.shape[0]):\n",
    "    counts = torch.bincount(selected_experts[i].flatten(), minlength=64)\n",
    "    expert_frequency[i] = counts\n",
    "print(\"expert_frequency shape\", expert_frequency.shape)\n",
    "print(\"expert_frequency\", expert_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy tensor([5.7442, 5.8317, 5.8564, 5.8119, 5.8006, 5.7841, 5.8014, 5.8049, 5.8122,\n",
      "        5.8377, 5.8217, 5.8190, 5.8210, 5.8035, 5.8613, 5.8114])\n",
      "average entropy tensor(5.8139)\n",
      "max entropy tensor(5.8613)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calculate_entropy(A):\n",
    "    A = A.float()\n",
    "    row_sums = A.sum(dim=-1, keepdim=True)\n",
    "    P = A / (row_sums + 1e-10)\n",
    "    P_log_P = P * torch.log2(P + 1e-10)\n",
    "    entropy = -P_log_P.sum(dim=-1)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "print(\"entropy\", calculate_entropy(expert_frequency))\n",
    "print(\"average entropy\", calculate_entropy(expert_frequency).mean())\n",
    "print(\"max entropy\", calculate_entropy(expert_frequency).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caee2596adaf4bb9bffc1022b6b887f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "layer:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "top_expert_frequency = []\n",
    "for layer in tqdm(range(logits.shape[0]), desc=\"layer\"):\n",
    "    top1_experts = torch.argmax(logits[layer], dim=1)  # 形状为 [2693448]\n",
    "\n",
    "    expert_logits = []\n",
    "    for expert_idx in tqdm(range(logits.shape[2]), desc=\"expert\", disable=True):\n",
    "        # 创建布尔掩码，标记出当前专家为 Top-1 的位置\n",
    "        mask = top1_experts == expert_idx  # 形状为 [2,693,448]\n",
    "        # 使用掩码筛选出对应的 logits\n",
    "        selected_logits = logits[layer, mask]\n",
    "        expert_logits.append(selected_logits)\n",
    "        # print(\"selected_logits shape\", selected_logits.shape)\n",
    "    top_expert_frequency.append(expert_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ce7f7736a34685a8487d2509301de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "layer:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  436,  1108,  1298,  ...,  3279,  1193,   574],\n",
      "         [ 4937,  4048,  4923,  ...,  5503,  2687,  2583],\n",
      "         [14547,  1325,  3942,  ...,  1808,  1982,  2361],\n",
      "         ...,\n",
      "         [ 4700,  5978,  6320,  ...,  1627,  2528,  2085],\n",
      "         [ 5737,  1813,  1958,  ...,  1149,  7014,  5733],\n",
      "         [   71,   190,    66,  ...,  4196,   794,   229]],\n",
      "\n",
      "        [[31251,  6176, 25945,  ...,  8402,  6312, 12937],\n",
      "         [11837, 10973, 15579,  ...,  1038,  3622,  7621],\n",
      "         [ 1709,  5118,  1351,  ...,  1273,   404,   670],\n",
      "         ...,\n",
      "         [ 1925,   696,  1372,  ..., 14740, 18572, 17881],\n",
      "         [  114,   969,   341,  ...,   668,   914,  2401],\n",
      "         [  720,  3171,  1169,  ..., 26983,   670,  2270]],\n",
      "\n",
      "        [[ 2614,  2189, 10781,  ...,  4094, 29594,  3557],\n",
      "         [ 1072,   222,  2631,  ...,  1198,  1842,   225],\n",
      "         [    4,     1,     8,  ...,   315,    38,    12],\n",
      "         ...,\n",
      "         [  959,    75,   268,  ...,  7891,  8631,   144],\n",
      "         [ 7088,  4623,   327,  ...,  1616,  1672,  2098],\n",
      "         [  696,   160,  2413,  ...,  5816,  1023, 10439]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  595,   162,  1790,  ...,   392,    44,  1395],\n",
      "         [   31,    19,   156,  ...,    33,     0,   351],\n",
      "         [  175,  1425,  1647,  ...,  3471,  8412,    17],\n",
      "         ...,\n",
      "         [  900,  8989,  3872,  ...,  4091,   215, 12417],\n",
      "         [   24,     0,   530,  ...,     3,    50,     3],\n",
      "         [  596, 12699,     9,  ...,  2526,  2063,     9]],\n",
      "\n",
      "        [[    1,   266,    28,  ...,    24,    91,    77],\n",
      "         [  231,  1009,  1312,  ...,  3152,  3542,  1422],\n",
      "         [  371,    42,   495,  ...,    57,   293,    59],\n",
      "         ...,\n",
      "         [    8,  3906,   121,  ...,   199,   462,   245],\n",
      "         [  520,   897,  1375,  ...,  1674,   256,  2269],\n",
      "         [ 2034,  7640,   743,  ...,  6789,  8087,  5660]],\n",
      "\n",
      "        [[    6,    77,    45,  ...,    12,    25,    84],\n",
      "         [   93,    65, 74066,  ...,   540,    95,     2],\n",
      "         [  421,    11,  5122,  ...,   168, 15008,   430],\n",
      "         ...,\n",
      "         [  158,    76,   284,  ...,  1845,  1133,  2312],\n",
      "         [   78,    20,  2584,  ...,    24,   661, 25723],\n",
      "         [  578,     3,  1034,  ...,     6,  2862, 11455]]], dtype=torch.int32)\n",
      "entropy tensor([[3.1916, 5.4258, 5.1442,  ..., 5.1028, 5.3191, 4.6220],\n",
      "        [5.4709, 5.5978, 5.4838,  ..., 5.1547, 5.5347, 4.7604],\n",
      "        [5.3699, 5.4323, 4.8032,  ..., 4.8534, 5.6027, 5.1168],\n",
      "        ...,\n",
      "        [4.6438, 3.5600, 4.2202,  ..., 4.9922, 4.5068, 5.1117],\n",
      "        [4.2461, 5.2311, 4.8874,  ..., 4.1935, 4.9264, 4.7400],\n",
      "        [4.3823, 3.7016, 4.9673,  ..., 4.3238, 4.1922, 3.5294]])\n",
      "average entropy tensor(4.7865)\n",
      "shape of entropy torch.Size([16, 64])\n"
     ]
    }
   ],
   "source": [
    "collaboration = torch.zeros(\n",
    "    (logits.shape[0], logits.shape[2], logits.shape[2] - 1), dtype=torch.int32\n",
    ")\n",
    "for layer in tqdm(range(logits.shape[0]), desc=\"layer\"):\n",
    "    for expert in tqdm(range(logits.shape[2]), desc=\"expert\", disable=True):\n",
    "        expert_logits = top_expert_frequency[layer][expert]\n",
    "        expert_logits[:, expert] = float(\"-inf\")\n",
    "        top_experts = torch.topk(expert_logits, k=7, dim=-1).indices\n",
    "        collaboration_frequency = torch.bincount(top_experts.flatten(), minlength=64)\n",
    "        mask = torch.arange(64) != expert\n",
    "        collaboration[layer, expert] = collaboration_frequency[mask]\n",
    "print(collaboration)\n",
    "print(\"entropy\", calculate_entropy(collaboration))\n",
    "print(\"average entropy\", calculate_entropy(collaboration).mean())\n",
    "print(\"shape of entropy\", calculate_entropy(collaboration).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
