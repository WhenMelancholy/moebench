{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "\n",
    "os.chdir(\"/n/home08/zkong/mufan/tmp/moebench/OLMo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"runs/0312-OLMoE-300M/latest\", trust_remote_code=True\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/n/home08/zkong/.conda/envs/olmo_pretrain/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py\u001b[39m(\u001b[92m936\u001b[39m)\u001b[36mfrom_pretrained\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m    935\u001b[39m             ipdb.set_trace()\n",
      "\u001b[32m--> 936\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m use_fast \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m config_tokenizer_class.endswith(\u001b[33m\"Fast\"\u001b[39m):\n",
      "\u001b[32m    937\u001b[39m                 tokenizer_class_candidate = f\"{config_tokenizer_class}Fast\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"runs/0312-OLMoE-300M/latest\", trust_remote_code=True, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='runs/0312-OLMoE-300M/latest', vocab_size=50280, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|padding|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"|||IP_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50277: AddedToken(\"|||EMAIL_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50278: AddedToken(\"|||PHONE_NUMBER|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50279: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m      model(*args, **kwargs)\n",
      "\u001b[31mType:\u001b[39m           OLMoForCausalLM\n",
      "\u001b[31mString form:\u001b[39m   \n",
      "OLMoForCausalLM(\n",
      "           (model): OLMo(\n",
      "           (transformer): ModuleDict(\n",
      "           (wte): Embedding(50304, 10 <...>    )\n",
      "           )\n",
      "           (ff_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
      "           )\n",
      "           )\n",
      "           )\n",
      "\u001b[31mFile:\u001b[39m           /n/netscratch/mzitnik_lab/Lab/zlkong/cache/modules/transformers_modules/latest/modeling_olmo.py\n",
      "\u001b[31mDocstring:\u001b[39m      Extremely barebones HF model wrapper.\n",
      "\u001b[31mInit docstring:\u001b[39m Initialize internal Module state, shared by both nn.Module and ScriptModule."
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]).cuda()\n",
    "output = model(input_ids, return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
